{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pdb\n",
    "import limix\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from numpy import asarray\n",
    "import xarray as xr\n",
    "from copy import deepcopy\n",
    "import os\n",
    "from os.path import join\n",
    "import simplejson as json\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "import pdb\n",
    "from glob import glob\n",
    "from joblib import Parallel, delayed\n",
    "import h5py\n",
    "import re\n",
    "from plot import plot_poisson_ordered, plot_distplots, plot_distplot\n",
    "from util import get_amelie_selection\n",
    "import h5py\n",
    "import dask\n",
    "import dask.dataframe\n",
    "import dask.array\n",
    "from urllib.request import urlopen\n",
    "import gzip\n",
    "try:\n",
    "    import ipfsapi\n",
    "    has_ipfs = True\n",
    "except ModuleNotFoundError:\n",
    "    has_ipfs = False\n",
    "\n",
    "\n",
    "if has_ipfs:\n",
    "    try:\n",
    "        ipfs = ipfsapi.connect('127.0.0.1', 5001)\n",
    "    except Exception:\n",
    "        has_ipfs = False\n",
    "\n",
    "only_hash = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data (Amelie's and Hannah's)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"data/traits-kinship-hannah-amelie.pkl\"):\n",
    "    data = pkl.load(open(\"data/traits-kinship-hannah-amelie.pkl\", \"rb\"))\n",
    "else:\n",
    "    url = \"http://ipfs.io/ipfs/QmXtFuoA3JTkhhpUpqh4dyu3FJLUG7DWAmXwUk1N2TMbAh\"\n",
    "    data = pkl.load(urlopen(url))\n",
    "    \n",
    "dst_folder = \"3\"\n",
    "if not os.path.exists(dst_folder):\n",
    "    os.mkdir(dst_folder)\n",
    "if not os.path.exists(join(dst_folder, 'phenotype')):\n",
    "    os.mkdir(join(dst_folder, 'phenotype'))\n",
    "if not os.path.exists(join(dst_folder, 'kinship')):\n",
    "    os.mkdir(join(dst_folder, 'kinship'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isbernoulli(x):\n",
    "    x = np.asarray(x, float)\n",
    "    u = np.unique(x)\n",
    "    if len(u) == 2:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def get_bernoulli(x):\n",
    "    x = np.asarray(x, float)\n",
    "    u = np.unique(x)\n",
    "    i0 = x == u[0]\n",
    "    i1 = x == u[1]\n",
    "    x[i0] = 0.0\n",
    "    x[i1] = 1.0\n",
    "    return x\n",
    "\n",
    "def isdiscrete(x):\n",
    "    x = np.asarray(x, float)\n",
    "    ok = np.isfinite(x)\n",
    "    return all(x[ok] == np.asarray(x[ok], int))\n",
    "\n",
    "def get_poisson(x):\n",
    "    x = np.asarray(x, float)\n",
    "    mi = min(x)    \n",
    "    if mi < 0:\n",
    "        x += -mi\n",
    "    return x\n",
    "\n",
    "def isnumber(x):\n",
    "    try:\n",
    "        np.asarray(x, float)\n",
    "    except ValueError:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(\"arrayexpress/HS.hdf5\", \"r\")\n",
    "samples = np.asarray(f[\"/imputed_genotypes/row_header/rat\"].value)\n",
    "samples = [i.decode() for i in samples]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data0 = deepcopy(data)\n",
    "remove = []\n",
    "for name in data0['measures'].columns.values:\n",
    "    if isnumber(data0['measures'].loc[:, name]) and isdiscrete(data0['measures'].loc[:, name]):\n",
    "        data0['measures'].loc[:, name] = get_poisson(data0['measures'].loc[:, name])\n",
    "    else:\n",
    "        remove.append(name)\n",
    "for name in remove:\n",
    "    del data0['measures'][name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:03<00:00,  6.82it/s]\n"
     ]
    }
   ],
   "source": [
    "f = h5py.File(\"arrayexpress/HS.hdf5\", \"r\")\n",
    "pos = []\n",
    "chrs = []\n",
    "for i in tqdm(range(1, 22)):\n",
    "    p = f[\"/imputed_genotypes/chr{}/col_header/pos\".format(i)].value\n",
    "    pos.append(p)\n",
    "    chrs.append([i] * len(p))\n",
    "f.close()\n",
    "\n",
    "pos = np.concatenate(pos).astype(float)\n",
    "chrs = np.concatenate(chrs).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "amelie_selection = get_amelie_selection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend MultiprocessingBackend with 10 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "# patts = [\"null_measures_normal_(.*)_quantile_gaussianize.json.pkl\",\n",
    "#          \"null_measures_normal_(.*)_mean_standardize.json.pkl\",\n",
    "#          \"null_ipheno_normal_(.*)_mean_standardize.json.pkl\",\n",
    "#          \"null_ipheno_normal_(.*)_quantile_gaussianize.json.pkl\",\n",
    "#          \"null_measures_poisson_(.*).json.pkl\"]\n",
    "\n",
    "patts = [\"null_measures_normal_(.*)_quantile_gaussianize.json.pkl\",\n",
    "         \"null_measures_poisson_(.*).json.pkl\"]\n",
    "\n",
    "patt2name = {'null_ipheno_normal_(.*)_mean_standardize.json.pkl':'INormalStd',\n",
    "             'null_ipheno_normal_(.*)_quantile_gaussianize.json.pkl':'INormalGau',\n",
    "             'null_measures_poisson_(.*).json.pkl':'MPoisson',\n",
    "             'null_measures_normal_(.*)_mean_standardize.json.pkl':'MNormalStd',\n",
    "             'null_measures_normal_(.*)_quantile_gaussianize.json.pkl':'MNormalGau'}\n",
    "\n",
    "def plot_this(d):\n",
    "    trait = d[0][\"trait\"]\n",
    "    pos = list(d[0][\"pos\"]) * 5\n",
    "    chrs = list(d[0][\"chrs\"]) * 5\n",
    "    amelie_selection = d[0][\"amelie_selection\"]\n",
    "    \n",
    "    data = {}\n",
    "    for i, di in enumerate(d):\n",
    "        with gzip.open(di[\"path\"], 'rb') as f:\n",
    "            data[di[\"model\"]] = pkl.load(f)\n",
    "    \n",
    "    for i, di in enumerate(d):\n",
    "        alpha = 0.01\n",
    "        pv = data[di[\"model\"]][\"pv\"]\n",
    "        if len(pv) != len(pos):\n",
    "            return None\n",
    "        trait = di[\"trait\"]\n",
    "        model = di[\"model\"]\n",
    "        dataframe = {\"pv\": pv, \"pos\": pos, \"chr\": chrs}\n",
    "        \n",
    "        df = pd.DataFrame(data=dataframe)\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        limix.plot.qqplot(df[\"pv\"])\n",
    "        ax = plt.gca()\n",
    "        if trait in amelie_selection:\n",
    "            ax.set_title(f\"{trait} - {model}\", color='red')\n",
    "        else:\n",
    "            ax.set_title(f\"{trait} - {model}\")\n",
    "        folder = f\"3/fig/null/{model}/{trait}\"\n",
    "        try:\n",
    "            os.makedirs(folder)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        plt.savefig(folder + \"/qqplot.png\", bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "args = []\n",
    "data = dict()\n",
    "for path in glob(join(dst_folder, \"*.json.pkl.gz\")):\n",
    "    filename = path.split(\"/\")[1]\n",
    "    for patt in patts:\n",
    "        match = re.match(patt, filename)\n",
    "        if match:\n",
    "            trait = match.groups(0)[0]\n",
    "            model = patt2name[patt]\n",
    "            if trait not in data:\n",
    "                data[trait] = []\n",
    "\n",
    "            data[trait].append({\"trait\": trait, \"model\": model, \"path\": path, \"pos\": pos,\n",
    "                                \"chrs\":chrs, \"amelie_selection\":amelie_selection})\n",
    "\n",
    "# N = int(sys.argv[1])\n",
    "# seed = int(sys.argv[2])\n",
    "\n",
    "# for (i, a) in enumerate(list(data.values())):\n",
    "#     if i % N == seed:\n",
    "#         plot_this(a)\n",
    "_ = Parallel(n_jobs=10, verbose=50, backend=\"multiprocessing\")(delayed(plot_this)(a) for a in list(data.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:lab]",
   "language": "python",
   "name": "conda-env-lab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
